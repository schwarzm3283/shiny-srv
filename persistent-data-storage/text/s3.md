#### Overview

Similarly to using Dropbox, another option that takes advantage of online file storage is Amazon S3. S3 stands for "simple storage service" and that's exactly why I decided to try it out - simple. Just like with Dropbox, you can host any type of file on S3.

Since each response is its own file, different responses can have different fields, so it's easy to change the form to have different fields (though doing that will make aggregating all the responses more tricky).

#### Setup

You need to have an [Amazon Web Services](http://aws.amazon.com/) account and create an S3 bucket. AWS gives you free hosting for your first year if you stay under certain usage limits. 

#### Details

You can use the [RAmazonS3](http://www.omegahat.org/RAmazonS3/) package to interact with S3 from R. Note that the package doesn't seem to be under active development and I ran into some errors with it, so I'm not sure it's a good idea to rely on it.

When saving the files, it is important to ensure that files get different names (so that two responses won't overwrite each other). My simple solution is to include 3 things in the filename for each response: the md5 hash of the response's content, some random number, the time of submission.

When loading the responses, simply read all files in the bucket separately and concatenate them all into one dataframe.
